# Tutorial_nnUNet

<p align="center">
  <img src="Images/schema.png" alt="masque" width="500"/>
</p>  

----

## ğŸ“š Sommaire

- [ğŸ§° PrÃ©requis â€“ Installation de nnU-Net v2](#-prÃ©requis--installation-de-nnu-net-v2)
- [Ã‰tape 0ï¸âƒ£ â€“ PrÃ©paration des masques](#Ã©tape-0ï¸âƒ£--prÃ©paration-des-masques)
- [Ã‰tape 1ï¸âƒ£ - Organisation des donnÃ©es](#Ã©tape-1ï¸âƒ£---organisation-des-donnÃ©es)
- [Ã‰tape 2ï¸âƒ£ - PrÃ©paration des donnÃ©es](#Ã©tape-2ï¸âƒ£---prÃ©paration-des-donnÃ©es)
- [Ã‰tape 3ï¸âƒ£ - Preprocessing des donnÃ©es](#Ã©tape-3ï¸âƒ£---preprocessing-des-donnÃ©es)
- [Ã‰tape 4ï¸âƒ£ - EntraÃ®nement sur cluster](#Ã©tape-4ï¸âƒ£---entraÃ®nement-sur-cluster)
- [Ã‰tape 5ï¸âƒ£ - PrÃ©diction sur les images de test](#Ã©tape-5ï¸âƒ£---prÃ©diction-sur-les-images-de-test)
- [Ã‰tape 6ï¸âƒ£ - Utilisation sur de nouvelles images](#Ã©tape-6ï¸âƒ£---utilisation-sur-de-nouvelles-images)

---

# ğŸ§° PrÃ©requis â€“ Installation de nnU-Net v2

```
# Cloner le dÃ©pÃ´t
git clone https://github.com/MIC-DKFZ/nnUNet.git
cd nnUNet

# Installer les dÃ©pendances
pip install -e .
```
---
# Ã‰tape 0ï¸âƒ£ â€“ PrÃ©paration des masques

Avant dâ€™utiliser nnU-Net, il faut que les masques de segmentation soient bien formatÃ©s, avec les classes correctement Ã©tiquetÃ©es :  
âš ï¸ le label 0 correspond au background (obligatoire pour nnU-Net)  

Pour rÃ©aliser la partie background, il faut aller dans la section *Data* de 3D Slicer puis, clique droit sur le masque et cliquer sur *Export visible segments to binary label map*.    
Une fois cela fait, aller dans la section *Segment editor* et dans *Source Volume*, chargÃ© ce nouveau masque binaire qui vient dÃªtre gÃ©nÃ©rÃ© :      
<p align="center">
  <img src="Images/exemple_masque.png" alt="masque" width="500"/>
</p>  

Ensuite, utiliser l'outil *Threshold* et cliquer sur une zone qui ne contient pas de pixels appartenant au masque (dans la zone verte sur l'exemple) et cliquer sur *Apply*.    
Pour finir, renommer ce nouveau segment *background*. 

---
# Ã‰tape 1ï¸âƒ£ - Organisation des donnÃ©es
La premiÃ¨re Ã©tape une fois que nnUNet est clÃ´nÃ© et compilÃ© est l'organisation des donnÃ©es afin de respecter le schÃ©ma souhaitÃ© par nnUNet. Il faut crÃ©er 3 dossiers :
```
3D_UNet
â””â”€â”€ nnUNet_results/
â””â”€â”€ nnUNet_raw/
â””â”€â”€ nnUNet_preprocessed/  
```
- **nnUNet_results** : va contenir les rÃ©sultats des entraÃ®nements (le laisser vide pour l'instant)  
- **nnUNet_preprocessed** : va contenir les images preprocessed par nnUNet (le laisser vide Ã©galement)  
- **nnUNet_raw** : va contenir les donnÃ©es utilisÃ©es pour l'entraÃ®nement et c'est ce dossier qui va nous intÃ©resser dans un premier temps puisque la disposition des donnÃ©es doit se faire de cette faÃ§on :  
```
nnUNet_raw/  
â””â”€â”€ DatasetXXX_name/  
    â”œâ”€â”€ imagesTr/  
    â”‚   â”œâ”€â”€ 001_0000.nrrd  # images de training   
    â”‚   â”œâ”€â”€ 002_0000.nrrd
    â”‚   â”œâ”€â”€ ...
    â”œâ”€â”€ labelsTr/  
    â”‚   â”œâ”€â”€ 001.nrrd       # masques de 3D Slicer  
    â”‚   â”œâ”€â”€ 002.nrrd
    â”‚   â”œâ”€â”€ ...
    â”œâ”€â”€ imagesTs/  
    â”‚   â”œâ”€â”€ 008.nrrd       # images de test  
    â”‚   â”œâ”€â”€ 009.nrrd
    â”‚   â”œâ”€â”€ ...
    â”œâ”€â”€ dataset.json       # fichier de configuration
```

âš ï¸ Le nom du couple image/masque est important. Exemple : l'image 001_0000.nrrd doit Ãªtre associÃ©e au masque 001.nrrd.  
âš ï¸ L'extension **.nnrd** est importante. Il est possible de converitr une image DICOM en .nrrd en la chargant dans 3D SLicer et en exportant l'image, de choisir l'extension souhaitÃ©e.   
âš ï¸ La sÃ©paration entre images de training et images de test se fait avec un ratio de 80/20% pour maximiser les performances.

## Ã‰criture du fichier de configuration :
### Exemple d'un fichier de configuration
```
{
    "name": "Dataset00X_name",
    "description": "Test_Segmentation",
    "tensorImageSize": "3D",
    "reference": "",
    "licence": "",
    "release": "1.0",
    "labels": {
        "background" : 0,
        "airways" : 1
    },
    "numTraining": 4,
    "numTest": 2,
    "training": [
        {"image": "./imagesTr/001_0000.nrrd", "label": "./labelsTr/001.nrrd"},
        {"image": "./imagesTr/002_0000.nrrd", "label": "./labelsTr/002.nrrd"},
        {"image": "./imagesTr/003_0000.nrrd", "label": "./labelsTr/003.nrrd"},
        {"image": "./imagesTr/004_0000.nrrd", "label": "./labelsTr/004.nrrd"},
    ],
    "test": [
        {"image": "./imagesTs/0_0000.nrrd"},
        {"image": "./imagesTs/012_0000.nrrd"}

    ],
    "channel_names": {
    "0": "CT"
    },
    "file_ending": ".nrrd"
}

```
- **name** : nom du dataset d'images (le mÃªme que celui prÃ©sent dans le dossier **nnUNet_raw**)
- **description** : indication sur la tÃ¢che de segmentation (pas nÃ©cessaire)
- **tensorImageSize** : laisser 3D pour les images du SPCCT
- **labels** : laisser le *background* en 0 et ensuite, lister sans ordre d'importance les autres classes du masques (parenchyme, lobes etc)
- **numTraining** : nombre d'images de training prÃ©sentes dans imagesTr
- **numTest** : nombre d'images de test prÃ©sentes dans imagesTs
- **training** : liste des couples image/masque du dataset
- **test** : liste des images prÃ©sentes dans imagesTs
- **channel_names** : laisser *CT* pour les images du SPCCT
- **file_ending** : laisser *.nrrd" si les images sonts exportÃ©s en *.nrrd*

---
# Ã‰tape 2ï¸âƒ£ - PrÃ©paration des donnÃ©es
âš ï¸ **AVANT** de continuer, il faut **export** les chemins vers ces dossiers dans l'environement qui va executer la commande pour effectuer le preprocessing.  
export nnUNet_raw="path/to/nnUNet_raw"
export nnUNet_preprocessed="path/to/nnUNet_preprocessed"
export nnUNet_results="path/to/nnUNet_results"

Une fois que les donnÃ©es sont organisÃ©es de la bonne faÃ§on. Il faut executer un script **correct.py** qui permet de corriger le nom et le numÃ©ro des classes.  
Comme Ã©voquÃ© prÃ©cÃ©demment, background **DOIT** avoir le label 0. Ensuite, l'ordre des classes n'importe pas.  

Le script **correct.py** permet de faire cela :
```
python3 correct.py --h
usage: correct.py [-h] --images_dir IMAGES_DIR --labels_dir LABELS_DIR --classes CLASSES [CLASSES ...]

Remappe les labels et redimensionne les segmentations.

optional arguments:
  -h, --help            show this help message and exit
  --images_dir IMAGES_DIR
                        Chemin vers le dossier des images
  --labels_dir LABELS_DIR
                        Chemin vers le dossier des labels
  --classes CLASSES [CLASSES ...]
                        Liste des classes utilisÃ©es dans le mapping

- **images_dir** : le chemin vers les images qui vont Ãªtre utilisÃ©es pour le training (avec le bon label pour chaque image ex: 001_0000.nrrd, ....)  
- **labels_dir** : le chemin vers les masques qui vont  Ãªtre utilisÃ©s pour le training (avec le bon label pour chaque image ex: 001.nrrd, ....)  
- **classes** : liste des noms des classes sans la classe **background**

De ce fait un exemple d'utilisation :
python3 correct.py --images_dir /path/to/images --labels_dir /path/to/masks --classes CLASSE1 CLASSE2


Une fois que le script a Ã©tÃ© executÃ©, on peut passer au preprocessing  
```

---
# Ã‰tape 3ï¸âƒ£ - Preprocessing des donnÃ©es

Pour cette Ã©tape, nous allons utilisÃ© **nnUNetv2_plan_and_preprocess** :
```
nnUNetv2_plan_and_preprocess -d XXX --verify_dataset_integrity --clean -c 3d_fullres
```

- **-d** : ce paramÃ¨tre correspond Ã  l'ID du dataset dejÃ  Ã©voquÃ© lors de la crÃ©ation du fichier de configuration  

Une fois que le script est executÃ© le dossier **nnUNet_preprocessed** ne devrait plus Ãªtre vide. On peut passer Ã  l'entraÃ®nement.

---
# Ã‰tape 4ï¸âƒ£ - EntraÃ®nement sur cluster

La premiÃ¨re Ã©tape est de copier les donnÃ©es sur le cluster :
```
scp -r /path/to/directory name@linux1.dg.creatis.insa-lyon.fr:/path/on/cluster
```

- **/path/to/directory** : mettre le chemin vers le dossier local contenant *nnUNet_raw*, *nnUNet_preprocessed* et *nnUNet_results*    
- **name** : nom de famille de l'utilisateur  
- **/path/on/cluster** : endroit oÃ¹ vous voulez stocker le dossier sur le cluster  

Une fois que les donnÃ©es sont sur le cluster nous allons pouvoir entraÃ®ner les modÃ¨les grÃ¢ce Ã  un fichier **.pbs**.

## Ã‰criture du fichier **.pbs** :
AprÃ¨s s'Ãªtre connectÃ© en *ssh* au cluster, on puet Ã©crire le script qui va executer l'entraÃ®nement :
### Exemple d'un fichier de **.pbs** :
```
#!/bin/sh
#PBS -l walltime=5:00:00
#PBS -N Nom
#PBS -l nodes=1:ppn=4:gpus=2
#PBS -q gpu
#PBS -l mem=64gb
#PBS -o Output0.out
#PBS -e Errors0.err
#PBS -m e
#PBS -M florian.davaux@creatis.insa-lyon.fr

export nnUNet_raw="path/to/nnUNet_raw"
export nnUNet_preprocessed="path/to/nnUNet_preprocessed"
export nnUNet_results="path/to/nnUNet_results"

conda activate env

nnUNetv2_train DatasetXXX_name 3d_fullres ID
```

- **premier paramÃ¨tre** : le temps que l'on souhaite accordÃ© Ã  l'entraÃ®nement du modÃ¨le  
- **deuxiÃ¨me paramÃ¨tre** : le nom qui va figurer dans la liste des codes lancÃ©s sur le cluster
- **troisiÃ¨me paramÃ¨tre** : le nombre de noeuds et gpus qu'on souhiate rÃ©server.  
**Conseil : minimum 2 gpus et 2 ppn pour un entraÃ®nement nnU-Net**  
- **quatriÃ¨me paramÃ¨tre** : le fait qu'on veuille reserver un ou plusieurs gpus  
- **cinquiÃ¨me paramÃ¨tre** : l'allocation de mÃ©moire.  
**Conseil : minimum 32gb pour un entraÃ®nement nnU-Net**
- **sixiÃ¨me paramÃ¨tre** : fichier qui va contenir les messages de sortie
- **septiÃ¨me paramÃ¨tre** : fichier qui va contenir les messages d'erreur

Ensuite, il faut **export** les chemins vers les dossiers *nnUNet_raw, nnUNet_preprocessed, nnUNet_results*.  
On active l'environnement.  
On lance la commande de training **nnUNet_train** :  
```
nnUNetv2_train DatasetXXX_name 3d_fullres ID
```

- **DatasetXXX_name** : nom du dataset
- **3d_fullres** : pour utiliser l'architexture 3D disponible
- **ID** : l'ID du fold qu'on veut entraÃ®ner sachant que nnU-Net utilise de la cross validation sur 5 folds.  

Pour voir l'avancement du script dans le cluster, on peut taper :
```
qstat -u name
```

- **name** : nom de l'utilisateur

Cette commande permet d'afficher l'Ã©tat d'avanceemnt du script lancÃ©.  

---

# Ã‰tape 5ï¸âƒ£ - PrÃ©diction sur les images de test
Une fois que les 5 modÃ¨les des 5 folds sont terminÃ©s, on peut recopier les donnÃ©es sur l'ordinateur en local :  

```
rsync -avzP name@linux1.dg.creatis.insa-lyon.fr:/path/on/cluster/to/nnUNet_results /path/to/directory/3D_UNet
```

- **name** : nom de famille de l'utilisateur  
- **/path/on/cluster/to/nnUNet_results** : endroit oÃ¹ est stockÃ© *nnUNet_results* sur le cluster  
- **/path/to/directory/3D_UNet** : mettre le chemin vers le dossier local qui contient les dossiers *nnUNet_raw, nnUNet_preprocessed, nnUNet_results*  

Maintenant que les rÃ©sultats sont stockÃ©s en local, on va pouvoir utiliser la prÃ©diction des modÃ¨les :
```
nnUNetv2_predict -i /path/to/imagesTs -o DIR -d XXX -c 3d_fullres -f ID
```

- **-i** : chemin vers les images de test
- **-o** : chemin du dossier qui va stocker les prÃ©dictions
- **-c** : architecture utilisÃ©e pour l'entraÃ®nement  
- **-d** : ce paramÃ¨tre correspond Ã  l'ID du dataset dejÃ  Ã©voquÃ© lors de la crÃ©ation du fichier de configuration  
- **-f** : l'ID du fold qu'on veut entraÃ®ner sachant que nnU-Net utilise de la cross validation sur 5 folds.

Si on veut utiliser l'*ensembling* du nnU-Net, c'est Ã  dire le fait de faire 5 prÃ©dictions diffÃ©rentes et finir par une moyenne des prÃ©dictions il faut lancer cette commande :
```
nnUNetv2_predict -i /path/to/imagesTs -o DIR -d XXX -c 3d_fullres -f 0 1 2 3 4
```
Ce qui change ici c'est que derriere ```-f```, on met ```0 1 2 3 4``` pour spÃ©cifier de faire la prÃ©diction avec les 5 modÃ¨les et non un suel et unique.

# Ã‰tape 6ï¸âƒ£ - Utilisation sur de nouvelles images

La vraie utilitÃ© d'un modÃ¨le prÃ©-entrainÃ© est de l'utiliser sur de nouvelles images.   
Il est possible d'exporter les modÃ¨les sous format zip. Il contiendront deux fichier, le fichier *.pth* contenant les poids du modÃ¨le et le fichier *dataset.json* du fold associÃ©. Puisqu'il est possible **UNIQUEMENT** d'exporter un fold choisi entre ceux entraÃ®nÃ©s (0, 1 ,2 ,3 ou 4).    

âš ï¸ Cependant, le fait de lancer une prÃ©diction sur un nouvel ordinaeur n'est pas encore disponible.  
De ce fait, si on veut lancer une prÃ©diction en local il va falloir modifier deux choses. Le dossier *imagesTs* ainsi que le fichier *dataset.json*.  

En effet, pour l'instant, le modÃ¨le s'attend Ã  ce que son nombre de prÃ©diction soit celui notÃ© dans le fichier *dataset.json*. L'astuce va Ãªtre de supprimer les images contenues dans *imagesTs*, de placer la ou les nouvelles images que l'on veut prÃ©dire et pour finir, ajuster le nombre de nouvelles images Ã  predir dans le fichier *dataset.json*.  

## Exemple prediction sur nouvelles images :
Exemple d'un modÃ¨le entraÃ®nÃ© et du fichier json associÃ© : 
```
3DUNet_LungsAirways
â”œâ”€â”€ nnUNet_preprocessed
â”‚Â Â  â””â”€â”€ Dataset001_lungsairways
â”‚Â Â      ...
â”œâ”€â”€ nnUNet_raw
â”‚Â Â  â””â”€â”€ Dataset001_lungsairways
â”‚Â Â      â”œâ”€â”€ dataset.json
â”‚Â Â      â”œâ”€â”€ imagesTr
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 001_0000.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 002_0000.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 003_0000.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 004_0000.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 005_0000.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 006_0000.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 007_0000.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 008_0000.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 009_0000.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 010_0000.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 011_0000.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 012_0000.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 013_0000.nrrd
â”‚Â Â      â”‚Â Â  â””â”€â”€ 014_0000.nrrd
â”‚Â Â      â”œâ”€â”€ imagesTs
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 015_0000.nrrd
â”‚Â Â      â”‚Â Â  â””â”€â”€ 016_0000.nrrd
â”‚Â Â      â”œâ”€â”€ labelsTr
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 001.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 002.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 003.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 004.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 005.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 006.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 007.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 008.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 009.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 010.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 011.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 012.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 013.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 014.nrrd
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 015.nrrd
â”‚Â Â      â”‚Â Â  â””â”€â”€ 016.nrrd
â”œâ”€â”€ nnUNet_results
â”‚Â Â  â””â”€â”€ Dataset001_lungsairways
â”‚Â Â      â””â”€â”€ nnUNetTrainer__nnUNetPlans__3d_fullres
â”‚Â Â          â”œâ”€â”€ dataset_fingerprint.json
â”‚Â Â          â”œâ”€â”€ dataset.json
â”‚Â Â          â”œâ”€â”€ fold_0
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ checkpoint_final.pth
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ checkpoint_latest.pth
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ debug.json
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ progress.png
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ training_log_2025_3_20_09_10_23.txt
â”‚Â Â          â”œâ”€â”€ fold_1
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ checkpoint_final.pth
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ checkpoint_latest.pth
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ debug.json
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ progress.png
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ training_log_2025_3_20_09_10_23.txt
â”‚Â Â          â”œâ”€â”€ fold_2
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ checkpoint_final.pth
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ checkpoint_latest.pth
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ debug.json
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ progress.png
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ training_log_2025_3_20_09_10_56.txt
â”‚Â Â          â”œâ”€â”€ fold_3
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ checkpoint_final.pth
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ checkpoint_latest.pth
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ debug.json
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ progress.png
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ training_log_2025_3_21_09_35_31.txt
â”‚Â Â          â”œâ”€â”€ fold_4
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ checkpoint_final.pth
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ checkpoint_latest.pth
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ debug.json
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ progress.png
â”‚Â Â          â”‚Â Â  â”œâ”€â”€ training_log_2025_3_21_09_36_54.txt
â”‚Â Â          â””â”€â”€ plans.json
```

Fichier **dataset.json** :
```
{
    "name": "Dataset001_lungsairways",
    "description": "Lungs and Airways segmentation dataset",
    "tensorImageSize": "3D",
    "reference": "",
    "licence": "",
    "release": "1.0",
    "labels": {
        "background" : 0,
        "lungs" : 1,
        "airways" : 2
    },
    "numTraining": 14,
    "numTest": 2,
    "training": [
        {"image": "./imagesTr/001_0000.nrrd", "label": "./labelsTr/001.nrrd"},
        {"image": "./imagesTr/002_0000.nrrd", "label": "./labelsTr/002.nrrd"},
        {"image": "./imagesTr/003_0000.nrrd", "label": "./labelsTr/003.nrrd"},
        {"image": "./imagesTr/004_0000.nrrd", "label": "./labelsTr/004.nrrd"},
        {"image": "./imagesTr/005_0000.nrrd", "label": "./labelsTr/005.nrrd"},
        {"image": "./imagesTr/006_0000.nrrd", "label": "./labelsTr/006.nrrd"},
        {"image": "./imagesTr/007_0000.nrrd", "label": "./labelsTr/007.nrrd"},
        {"image": "./imagesTr/008_0000.nrrd", "label": "./labelsTr/008.nrrd"},
        {"image": "./imagesTr/009_0000.nrrd", "label": "./labelsTr/009.nrrd"},
        {"image": "./imagesTr/010_0000.nrrd", "label": "./labelsTr/010.nrrd"},
        {"image": "./imagesTr/011_0000.nrrd", "label": "./labelsTr/011.nrrd"},
        {"image": "./imagesTr/012_0000.nrrd", "label": "./labelsTr/012.nrrd"},
        {"image": "./imagesTr/013_0000.nrrd", "label": "./labelsTr/013.nrrd"},
        {"image": "./imagesTr/014_0000.nrrd", "label": "./labelsTr/014.nrrd"}
    ],
    "test": [
        {"image": "./imagesTs/015_0000.nrrd"},
        {"image": "./imagesTs/016_0000.nrrd"}

    ],
    "channel_names": {
    "0": "CT"
    },
    "file_ending": ".nrrd"
}
```

Dans cet exemple, il y a 2 images de tests comme indiquÃ© dans le fichier *.json* dnas la valeur **numTest** et **test**.  

Si on souhaite prÃ©dire d'autres images, il faut donc vider le dossier **imagesTs**, mettre les images qui doivent Ãªtre prÃ©dites dnas **imagesTs**, et modifier en consÃ©quence **numTest** et **test** dans le fichier *dataset.json*.  

Enuite on peut rÃ©utiliser la commande ```nnUNet_predict```.
