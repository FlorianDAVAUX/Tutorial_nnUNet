# Tutorial_nnUNet


---

# ğŸ§° PrÃ©requis â€“ Installation de nnU-Net v2

```
# Cloner le dÃ©pÃ´t
git clone https://github.com/MIC-DKFZ/nnUNet.git
cd nnUNet

# Installer les dÃ©pendances
pip install -e .
```
---
# Ã‰tape 0ï¸âƒ£ â€“ PrÃ©paration des masques

Avant dâ€™utiliser nnU-Net, il faut que les masques de segmentation soient bien formatÃ©s, avec les classes correctement Ã©tiquetÃ©es :  
âš ï¸ le label 0 correspond au background (obligatoire pour nnU-Net)  

Pour rÃ©aliser la partie background, il faut aller dans la section *Data* de 3D Slicer puis, clique droit sur le masque et cliquer sur *Export visible segments to binary label map*.    
Une fois cela fait, aller dans la section *Segment editor* et dans *Source Volume*, chargÃ© ce nouveau masque binaire qui vient dÃªtre gÃ©nÃ©rÃ©.     
METTRE UN EXEMPLE DE MASQUE BINAIRE  
Ensuite, utiliser l'outil *Threshold* et cliquer sur une zone qui ne contient pas de pixels appartenant au masque (une zone noire) et cliquer sur *Apply*.    
Pour finir, renommer ce nouveau segment en *background*.

---
# Ã‰tape 1ï¸âƒ£ - Organisation des donnÃ©es
La premiÃ¨re Ã©tape une fois que nnUNet est clÃ´nÃ© et compilÃ© est l'organisation des donnÃ©es afin de respecter le schÃ©ma souhaitÃ© par nnUNet. Il faut crÃ©er 3 dossiers :
```
3D_UNet
â””â”€â”€ nnUNet_results/
â””â”€â”€ nnUNet_raw/
â””â”€â”€ nnUNet_preprocessed/  
```
- **nnUNet_results** : va contenir les rÃ©sultats des entraÃ®nements (le laisser vide pour l'instant)  
- **nnUNet_preprocessed** : va contenir les images preprocessed par nnUNet (le laisser vide Ã©galement)  
- **nnUNet_raw** : va contenir les donnÃ©es utilisÃ©es pour l'entraÃ®nement et c'est ce dossier qui va nous intÃ©resser dans un premier temps puisque la disposition des donnÃ©es doit se faire de cette faÃ§on :  
```
nnUNet_raw/  
â””â”€â”€ DatasetXXX_name/  
    â”œâ”€â”€ imagesTr/  
    â”‚   â”œâ”€â”€ 001_0000.nrrd  # images de training   
    â”‚   â”œâ”€â”€ 002_0000.nrrd
    â”‚   â”œâ”€â”€ ...
    â”œâ”€â”€ labelsTr/  
    â”‚   â”œâ”€â”€ 001.nrrd       # masques de 3D Slicer  
    â”‚   â”œâ”€â”€ 002.nrrd
    â”‚   â”œâ”€â”€ ...
    â”œâ”€â”€ imagesTs/  
    â”‚   â”œâ”€â”€ 008.nrrd       # images de test  
    â”‚   â”œâ”€â”€ 009.nrrd
    â”‚   â”œâ”€â”€ ...
    â”œâ”€â”€ dataset.json       # fichier de configuration
```

âš ï¸ Le nom du couple image/masque est important. Exemple : l'image 001_0000.nrrd doit Ãªtre associÃ©e au masque 001.nrrd.  
âš ï¸ L'extension **.nnrd** est importante. Il est possible de converitr une image DICOM en .nrrd en la chargant dans 3D SLicer et en exportant l'image, de choisir l'extension souhaitÃ©e.   
âš ï¸ La sÃ©paration entre images de training et images de test se fait avec un ratio de 80/20% pour maximiser les performances.

## Ã‰criture du fichier de configuration :
### Exemple d'un fichier de configuration
```
{
    "name": "Dataset00X_name",
    "description": "Test_Segmentation",
    "tensorImageSize": "3D",
    "reference": "",
    "licence": "",
    "release": "1.0",
    "labels": {
        "background" : 0,
        "airways" : 1
    },
    "numTraining": 4,
    "numTest": 2,
    "training": [
        {"image": "./imagesTr/001_0000.nrrd", "label": "./labelsTr/001.nrrd"},
        {"image": "./imagesTr/002_0000.nrrd", "label": "./labelsTr/002.nrrd"},
        {"image": "./imagesTr/003_0000.nrrd", "label": "./labelsTr/003.nrrd"},
        {"image": "./imagesTr/004_0000.nrrd", "label": "./labelsTr/004.nrrd"},
    ],
    "test": [
        {"image": "./imagesTs/0_0000.nrrd"},
        {"image": "./imagesTs/012_0000.nrrd"}

    ],
    "channel_names": {
    "0": "CT"
    },
    "file_ending": ".nrrd"
}

```
- **name** : nom du dataset d'images (le mÃªme que celui prÃ©sent dans le dossier **nnUNet_raw**)
- **description** : indication sur la tÃ¢che de segmentation (pas nÃ©cessaire)
- **tensorImageSize** : laisser 3D pour les images du SPCCT
- **labels** : laisser le *background* en 0 et ensuite, lister sans ordre d'importance les autres classes du masques (parenchyme, lobes etc)
- **numTraining** : nombre d'images de training prÃ©sentes dans imagesTr
- **numTest** : nombre d'images de test prÃ©sentes dans imagesTs
- **training** : liste des couples image/masque du dataset
- **test** : liste des images prÃ©sentes dans imagesTs
- **channel_names** : laisser *CT* pour les images du SPCCT
- **file_ending** : laisser *.nrrd" si les images sonts exportÃ©s en *.nrrd*

---
# Ã‰tape 2ï¸âƒ£ - PrÃ©paration des donnÃ©es
âš ï¸ **AVANT** de continuer, il faut **export** les chemins vers ces dossiers dans l'environement qui va executer la commande pour effectuer le preprocessing.  
```
export nnUNet_raw="path/to/nnUNet_raw"
export nnUNet_preprocessed="path/to/nnUNet_preprocessed"
export nnUNet_results="path/to/nnUNet_results"
```
Une fois que les donnÃ©es sont organisÃ©es de la bonne faÃ§on. Il faut executer un script **correct.py** qui permet de corriger le nom et le numÃ©ro des classes.  
Comme Ã©voquÃ© prÃ©cÃ©demment, background **DOIT** avoir le label 0. Ensuite, l'ordre des classes n'importe pas.

